{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd377ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from agents import Agent, Runner\n",
    "from agents.extensions.models.litellm_model import LitellmModel\n",
    "from dotenv import load_dotenv\n",
    "import asyncio\n",
    "\n",
    "load_dotenv()\n",
    "MODEL = 'gemini/gemini-2.0-flash'\n",
    "gemni_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "# Basic agent (optional)\n",
    "agent = Agent(\n",
    "    name=\"Assistant\",\n",
    "    instructions=\"basic agent.\",\n",
    "    model=LitellmModel(model=MODEL, api_key=gemni_api_key),\n",
    ")\n",
    "\n",
    "# Joke generator agent\n",
    "joke_agent = Agent(\n",
    "    name=\"joke agent\",\n",
    "    instructions=\"generate a random computer joke\",\n",
    "    model=LitellmModel(model=MODEL, api_key=gemni_api_key),\n",
    ")\n",
    "\n",
    "# Language translator agent\n",
    "language_agent = Agent(\n",
    "    name=\"language_agent\",\n",
    "    instructions=\"You translate the joke into Urdu.\",\n",
    "    model=LitellmModel(model=MODEL, api_key=gemni_api_key),\n",
    "    \n",
    ")\n",
    "\n",
    "async def run():\n",
    "    topic = \"Tell me a computer joke\"\n",
    "\n",
    "    # Step 1: Generate joke\n",
    "    joke_result = await Runner.run(joke_agent, topic)\n",
    "    print(\"English Joke:\", joke_result.final_output)\n",
    "\n",
    "    # Step 2: Translate joke to Urdu\n",
    "    translation_result = await Runner.run(language_agent, joke_result.final_output)\n",
    "    print(\"Urdu Joke:\", translation_result.final_output)\n",
    "\n",
    "# Run the function\n",
    "await run()\n",
    "\n",
    "    # model=LitellmModel(model=MODEL, api_key=gemni_api_key),"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea98b766",
   "metadata": {},
   "source": [
    "RECIPE MAKER AGENT BY PYDANTIC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f65df04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from pydantic import BaseModel\n",
    "from agents.extensions.models.litellm_model import LitellmModel\n",
    "from agents import Agent , Runner\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "MODEL = 'gemini/gemini-2.0-flash'\n",
    "gemni_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "class Recipe(BaseModel):\n",
    "    title:str\n",
    "    ingridiants:str\n",
    "    cooking_time:int\n",
    "\n",
    "Recipe_agent = Agent(\n",
    "    name = \"recipe maker agent\",\n",
    "    instructions = \"you make a recipe base on user input\",\n",
    "    model=LitellmModel(model=MODEL,api_key=gemni_api_key),\n",
    "    output_type = Recipe\n",
    ")\n",
    "\n",
    "result = await Runner.run(Recipe_agent,\"make chicken charahi\")\n",
    "# print(result.final_output)\n",
    "all_data = result.final_output.dict()\n",
    "# print(all_data)\n",
    "for i,j in all_data.items():\n",
    "    print(f\"({i} === ({j}))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7eb6643",
   "metadata": {},
   "source": [
    "TOOL CALLING / FUNCTION CALLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa074a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "from agents import Agent, function_tool, Runner , WebSearchTool\n",
    "from agents.extensions.models.litellm_model import LitellmModel\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load env\n",
    "load_dotenv()\n",
    "\n",
    "MODEL = 'gemini/gemini-2.0-flash'\n",
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")  # fixed spelling\n",
    "\n",
    "# Tool function must accept city as input\n",
    "# @function_tool\n",
    "# def get_weather(city: str) -> str:\n",
    "#     print(f\"Getting weather of {city}\")\n",
    "#     return f\"The weather in {city} is sunny â˜€ï¸\"\n",
    "\n",
    "# @function_tool\n",
    "# def get_temperature(city:str) -> str:\n",
    "#     print(f\"fetch temperature of {city}\")\n",
    "#     return f\"the temperature of {city} is 70\"\n",
    "# # Define the agent\n",
    "# agent = Agent(\n",
    "#     name=\"weather_agent\",\n",
    "#     instructions=\"You are a local weather assistant. Use the tool to tell the weather of any city.\",\n",
    "#     model=LitellmModel(model=MODEL, api_key=gemini_api_key),\n",
    "#     tools=[get_weather,get_temperature]\n",
    "# )\n",
    "\n",
    "# # Run inside async function\n",
    "# result = await Runner.run(agent, \"how old is the moon\")\n",
    "# print(result.final_output)\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"get news agent for user\",\n",
    "    instructions=\"You are a local news reporter which tells the news.\",\n",
    "    model=LitellmModel(model=MODEL, api_key=gemini_api_key),\n",
    ")\n",
    "\n",
    "# Run inside async function\n",
    "result = await Runner.run(agent, \"news about most important global news in easy english wording \")\n",
    "print(result.final_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dab40b",
   "metadata": {},
   "source": [
    "NEWS AND SPEAK BY PYTTSX3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51eefec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pyttsx3  # text to speech\n",
    "from agents import Agent, Runner\n",
    "from agents.extensions.models.litellm_model import LitellmModel\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Model details\n",
    "MODEL = 'gemini/gemini-2.0-flash'\n",
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "# Create the Agent\n",
    "agent = Agent(\n",
    "    name=\"get a intermediate vocabliry for user\",\n",
    "    instructions=\"You are a local english tutor which tells the 1 vocublary word to user and in english and then translate it in urdu and give one only one easy word in urdu which is more spoken by pakistani, and translet word is also is in english.\",\n",
    "    model=LitellmModel(model=MODEL, api_key=gemini_api_key),\n",
    ")\n",
    "\n",
    "# Text-to-Speech function\n",
    "def speak(text):\n",
    "    engine = pyttsx3.init()\n",
    "    engine.setProperty('rate', 150)\n",
    "    engine.setProperty('volume', 1.0)\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "    engine.stop()  # prevents ReferenceError\n",
    "\n",
    "# Run the agent using await (works in Jupyter)\n",
    "result = await Runner.run(agent, \"tell me a new vocabliry word\")\n",
    "\n",
    "# Clean up the output\n",
    "clean_text = result.final_output.replace(\"*\", \"\")\n",
    "print(clean_text)\n",
    "\n",
    "# Speak the news\n",
    "speak(clean_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5a1a82",
   "metadata": {},
   "source": [
    "HANDSOFF-CONCEPTS  (IN THIS CODE ONLY THE ERROR IS BY MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fb56f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from agents import Agent, Runner\n",
    "from agents.extensions.models.litellm_model import LitellmModel\n",
    "from pydantic import BaseModel\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Model details\n",
    "MODEL=\"gpt-4-1106-preview\"\n",
    "\n",
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "# Joke output type in English\n",
    "class EnglishJokeType(BaseModel):\n",
    "    joke_in_english: str\n",
    "\n",
    "# Joke output type in Urdu\n",
    "class UrduJokeType(BaseModel):\n",
    "    joke_in_urdu: str\n",
    "\n",
    "# Agent 1: Joke Creator\n",
    "joke_agent = Agent(\n",
    "    name=\"joke agent\",\n",
    "    instructions=\"You tell a new joke based on user input.\",\n",
    "    model=LitellmModel(model=MODEL, api_key=gemini_api_key),\n",
    "    output_type=EnglishJokeType\n",
    ")\n",
    "\n",
    "# Agent 2: Translator\n",
    "translator_agent = Agent(\n",
    "    name=\"joke translator agent\",\n",
    "    instructions=\"You translate the given joke into Urdu.\",\n",
    "    model=LitellmModel(model=MODEL, api_key=gemini_api_key),\n",
    "    output_type=UrduJokeType\n",
    ")\n",
    "\n",
    "# Handoff: joke_agent â†’ translator_agent\n",
    "joke_agent.handoffs = [translator_agent] \n",
    "\n",
    "# Run the system\n",
    "result = await Runner.run(joke_agent, \"tell me a computer joke\")\n",
    "print(result.final_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc624dd7",
   "metadata": {},
   "source": [
    "HAND_OFF AND further concepts + TRACING CONCEPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8ece84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from agents import Agent, Runner\n",
    "from agents.extensions.models.litellm_model import LitellmModel\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# âœ… Tracing import\n",
    "from agents.tracing import trace  # make sure this import exists!\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Model info\n",
    "MODEL = \"gemini/gemini-1.5-flash\"\n",
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "if not gemini_api_key:\n",
    "    raise ValueError(\"âŒ GEMINI_API_KEY not found in .env file!\")\n",
    "\n",
    "# Callbacks\n",
    "def on_math(clean_text, runcontextwrapper):\n",
    "    print(\"ðŸ‘‰ Handing off to MATH agent...\")\n",
    "    print(\"âœ… on_math() called.\")\n",
    "\n",
    "def on_history(clean_text, runcontextwrapper):\n",
    "    print(\"ðŸ‘‰ Handing off to HISTORY agent...\")\n",
    "    print(\"âœ… on_history() called.\")\n",
    "\n",
    "# Agents\n",
    "math_agent = Agent(\n",
    "    name=\"math_tutor_agent\",\n",
    "    instructions=\"You help users solve math questions.\",\n",
    "    model=LitellmModel(model=MODEL, api_key=gemini_api_key)\n",
    ")\n",
    "\n",
    "history_agent = Agent(\n",
    "    name=\"history_tutor_agent\",\n",
    "    instructions=\"You answer user questions about history.\",\n",
    "    model=LitellmModel(model=MODEL, api_key=gemini_api_key)\n",
    ")\n",
    "\n",
    "guess_agent = Agent(\n",
    "    name=\"guess_agent\",\n",
    "    instructions=\"You decide if a question is about math or history and pass it to the correct agent. Announce which agent is handling it before solving and also write the answer.\",\n",
    "    model=LitellmModel(model=MODEL, api_key=gemini_api_key),\n",
    "    handoffs=[\n",
    "        {\"agent\": math_agent, \"on_hand\": on_math},\n",
    "        {\"agent\": history_agent, \"on_hand\": on_history}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# âœ… Traced run\n",
    "with trace(\"ðŸ” Tracing Guess Agent\"):\n",
    "    user_input_1 = \"when did columbus discover america , write date?\"\n",
    "    result_1 = await Runner.run(guess_agent, user_input_1)\n",
    "    print(\"ðŸ§  Response 1:\", result_1.final_output)\n",
    "\n",
    "    user_input_2 = \"What is 15 + 30?\"\n",
    "    result_2 = await Runner.run(guess_agent, user_input_2)\n",
    "    print(\"ðŸ§  Response 2:\", result_2.final_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06011c2a",
   "metadata": {},
   "source": [
    "GUARDIALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8afb612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title === Simple Beef Stir-fry\n",
      "ingredients === 1 lb beef sirloin, thinly sliced\n",
      "1 tbsp vegetable oil\n",
      "1 onion, chopped\n",
      "2 cloves garlic, minced\n",
      "1 red bell pepper, sliced\n",
      "1 green bell pepper, sliced\n",
      "1 cup broccoli florets\n",
      "1/2 cup soy sauce\n",
      "1/4 cup brown sugar\n",
      "2 tbsp cornstarch\n",
      "1/4 cup water\n",
      "cooking_time === 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24312/2620857558.py:73: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  recipe = result.final_output.dict()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from agents import (\n",
    "    GuardrailFunctionOutput,\n",
    "    InputGuardrailTripwireTriggered,\n",
    "    RunContextWrapper,\n",
    "    TResponseInputItem,\n",
    "    input_guardrail,\n",
    "    Agent,\n",
    "    Runner,\n",
    ")\n",
    "from pydantic import BaseModel\n",
    "from agents.extensions.models.litellm_model import LitellmModel\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Model info\n",
    "MODEL = \"gemini/gemini-1.5-flash\"\n",
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "if not gemini_api_key:\n",
    "    raise ValueError(\"âŒ GEMINI_API_KEY not found in .env file!\")\n",
    "\n",
    "\n",
    "# âœ… Step 1: Guardrail output model\n",
    "class RecipeCheckOutput(BaseModel):\n",
    "    is_bad_request: bool\n",
    "    reason: str\n",
    "\n",
    "\n",
    "# âœ… Step 2: Guardrail agent\n",
    "guardrail_agent = Agent(\n",
    "    name=\"Recipe Guard Agent\",\n",
    "    instructions=\"Check if the user is asking for an illegal, unsafe, or inappropriate recipe (like drugs, alcohol, poison, etc).\",\n",
    "    model=LitellmModel(model=MODEL, api_key=gemini_api_key),\n",
    "    output_type=RecipeCheckOutput,\n",
    ")\n",
    "\n",
    "\n",
    "# âœ… Step 3: Input guardrail function\n",
    "@input_guardrail\n",
    "async def recipe_input_guardrail(\n",
    "    ctx: RunContextWrapper[None],\n",
    "    agent: Agent,\n",
    "    input: str | list[TResponseInputItem]\n",
    ") -> GuardrailFunctionOutput:\n",
    "    result = await Runner.run(guardrail_agent, input, context=ctx.context)\n",
    "    return GuardrailFunctionOutput(\n",
    "        output_info=result.final_output,\n",
    "        tripwire_triggered=result.final_output.is_bad_request,\n",
    "    )\n",
    "\n",
    "\n",
    "# âœ… Step 4: Main agent output model\n",
    "class Recipe(BaseModel):\n",
    "    title: str\n",
    "    ingredients: str\n",
    "    cooking_time: int\n",
    "\n",
    "\n",
    "# âœ… Step 5: Recipe agent with input guardrail\n",
    "Recipe_agent = Agent(\n",
    "    name=\"recipe maker agent\",\n",
    "    instructions=\"You make a recipe based on user input.\",\n",
    "    model=LitellmModel(model=MODEL, api_key=gemini_api_key),\n",
    "    output_type=Recipe,\n",
    "    input_guardrails=[recipe_input_guardrail],\n",
    ")\n",
    "\n",
    "\n",
    "# âœ… Step 6: Run the agent with exception handling\n",
    "try:\n",
    "    result = await Runner.run(Recipe_agent, \"how to make beef\")\n",
    "    recipe = result.final_output.dict()\n",
    "    for key, value in recipe.items():\n",
    "        print(f\"{key} === {value}\")\n",
    "\n",
    "except InputGuardrailTripwireTriggered:\n",
    "    print(\"ðŸš« Input Blocked: The recipe request was inappropriate!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "682570db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why was the computer cold?  Because it left its Windows open!\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from agents import Agent, Runner\n",
    "from agents.extensions.models.litellm_model import LitellmModel\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "MODEL = \"gemini/gemini-1.5-flash\"\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"Joke Agent\",\n",
    "    instructions=\"Tell a funny computer-related joke.\",\n",
    "    model=LitellmModel(model=MODEL, api_key=api_key),\n",
    ")\n",
    "\n",
    "async def main():\n",
    "    result = await Runner.run(agent, \"Tell me a computer joke\")\n",
    "    joke = str(result.final_output)\n",
    "\n",
    "    # Fake streaming: show characters one by one\n",
    "    for char in joke:\n",
    "        print(char, end=\"\", flush=True)\n",
    "        await asyncio.sleep(0.03)  # Delay to mimic typing\n",
    "\n",
    "await main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
